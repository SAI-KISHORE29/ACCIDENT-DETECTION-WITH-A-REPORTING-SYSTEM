{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c20982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d50c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1ec509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2529c706220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da41986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8119c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7cf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2555ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21006e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af20a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb02ec43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57001716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586cff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e00a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 0.8581 - accuracy: 0.5935 - val_loss: 0.9152 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.4959 - accuracy: 0.8000 - val_loss: 0.8639 - val_accuracy: 0.7313\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.3314 - accuracy: 0.8645 - val_loss: 0.8843 - val_accuracy: 0.7463\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1208 - accuracy: 0.9484 - val_loss: 0.8736 - val_accuracy: 0.6716\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.1477 - accuracy: 0.9355 - val_loss: 0.8374 - val_accuracy: 0.7164\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0673 - accuracy: 0.9935 - val_loss: 0.8561 - val_accuracy: 0.7910\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0658 - accuracy: 0.9871 - val_loss: 0.7938 - val_accuracy: 0.7463\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0361 - accuracy: 0.9935 - val_loss: 0.7921 - val_accuracy: 0.7612\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.7612\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8060\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8209\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8358\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.7910\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.7761\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.7761\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.7761\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.8060\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.8209\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.8209\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.7910\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.7422 - val_accuracy: 0.7910\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.8060\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8209\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8209\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8209\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8209\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8060\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7508 - val_accuracy: 0.8209\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8209\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8209\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.8209\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8209\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.8209\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8209\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.8209\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8209\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8209\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.8209\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7627 - val_accuracy: 0.8209\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8209\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.8209\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7656 - val_accuracy: 0.8209\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.8209\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7689 - val_accuracy: 0.8209\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8209\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8209\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.8209\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.8209\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.8209\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.8209\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7750 - val_accuracy: 0.8209\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.8209\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7823 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.8209\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.8209\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.8209\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7892 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.8209\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.8209\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.8209\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 9.9927e-04 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.8358\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 9.7975e-04 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 9.6228e-04 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 9.4197e-04 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 9.2601e-04 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.8209\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 9.0990e-04 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.8209\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 8.9377e-04 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.8358\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 8.7656e-04 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.8358\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 8.5938e-04 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.8358\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 8.4693e-04 - accuracy: 1.0000 - val_loss: 0.8069 - val_accuracy: 0.8358\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 8.3140e-04 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.8358\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 8.1714e-04 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.8358\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 8.0306e-04 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.8209\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 7.8824e-04 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.8358\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 7.7558e-04 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.8209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2529ebbae80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "494768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d52fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(3) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf0f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9047ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1260b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f69282",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "721c02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb5b165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0004301e-05 9.9998999e-01]\n",
      " [4.8785133e-04 9.9951220e-01]\n",
      " [2.5489139e-03 9.9745113e-01]\n",
      " [7.7405886e-04 9.9922597e-01]\n",
      " [1.9390254e-03 9.9806100e-01]\n",
      " [3.8881668e-01 6.1118340e-01]\n",
      " [7.8325033e-01 2.1674965e-01]\n",
      " [5.8117330e-01 4.1882670e-01]\n",
      " [7.5333416e-01 2.4666581e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f040ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e66b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "dir_path ='C:/Users/Admin/Desktop/AccidentDetection/Test'\n",
    "account_sid = 'AC972d8be06c5f87bafcaf7f9e955e878f'\n",
    "auth_token = '30d776ceb030aa3331c2690adf505395'\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_='+19125518743',\n",
    "                 to='+919789829598')\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab12e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
